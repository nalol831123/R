n=50,
since = '2018-03-19',
until = '2018-03-26')
tweets
tweets.list <- twListToDF(tweets)
names.list <-  rbindlist(lapply(tweets.list$screenName,
as.data.frame))
tweets.list$screenName
names.list
tweets.list
names(names.list)[1] <- "Name"
names.list
tweets.list
alldata <- data.frame()
for (i in 1:3){ #Cursor
tryCatch(
{
# get name from '#_______' users list
tag.user <- names.list$Name[i]
# print query location
print(paste(i, tag.user))
# get User's twitter account
tag.user.account <- getUser(tag.user)
# get account's friend (if accessible)
user.friends <- tag.user.account$getFriends(retryOnRateLimit=180)
print(length(user.friends))
# limit
if (length(user.friends) < 3000){
# Make data.table of user's friends data list.
friends.df <- rbindlist(lapply(user.friends, as.data.frame))
# Get the only friends name column.
friends.name.df <- data.frame(tempname=c(friends.df$name))
# Change column name
colname <- toString(tag.user)
setnames(friends.name.df, c(colname))
# Write table
write.table(friends.name.df, file = paste(colname, ".csv"))
# bind data in the same data.frame
alldata <- rbind.fill(alldata, friends.name.df)
#data <- cbind(list(data, friends.name.df))
}
else{
print(paste(i, tag.user, "<== friends count > 500"))
}
},
warning = function(w){},
error = function(e){
#ERROR (need to store it?)
print(paste("ERROR", tag.user))
},
finally = {
print("End Try&Catch")
})
i = i+1
}
install.packages("RCurl")
library(RCurl)
library(twitteR)
install.packages("bitops")
install.packages("bitops")
library(RCurl)
library(twitteR)
library(bitops)
library(RCurl)
consumerKey <- "eIaUSZ0CW1baBIawv6aO3yGhA"
consumerSecret <- "U8ceWsFc8lymqRtfhK1b1QQR1DFvDUPUORbBNkYy4ziOiOhk3a"
accessToken <- "978170993544806400-lb7cs4vPkCtbHqwCO6vynaMceKRs0Ig"
accessSecret <- "ewPYmyyGWce0ZgOpITkqJxJ8hVbKzkSZqecSG6Tjx6wD4"
setup_twitter_oauth(consumerKey, consumerSecret, accessToken, accessSecret)
nba_tweets <- search("NBA", n = 100, lang= "en")
nba_tweets <- searchTwitter("NBA", n = 100, lang= "en")
nba_tweets
nba_tweets [1:3]
library(tm)
library(NLP)
library(tm)
install.packages("wordcloud")
library(wordcloud)
install.packages("RColorBrewer")
install.packages("RColorBrewer")
library(RColorBrewer)
library(wordcloud)
class(nba_tweets)
nba_tweets_text <- sapply(nba_tweets, function(x) x$getText())
str(nba_tweets_text)
nba_corpus <- Corpus(VectorSource(nba_tweets_text))
library(tm)
library(tm)
library(NLP)
nba_corpus <- Corpus(VectorSource(nba_tweets_text))
nba_corpus
inspect(nba_corpus[1])
inspect(nba_corpus[66])
nba_corpus_clean <- tm_map(nba_corpus, removePunctuation)
inspect(nba_corpus_clean[66])
nba_corpus_clean <- tm_map(nba_corpus_clean, content_transformer(tolower))
nba_corpus_clean <- tm_map(nba_corpus_clean, content_transformer(tolower))
inspect(nba_corpus_clean[Harden])
inspect(nba_corpus_clean["Harden"])
inspect(nba_corpus_clean[8])
inspect(nba_corpus_clean[2])
library(wordcloud)
nba_corpus_clean
nba_tweets <- searchTwitter("NBA", n = 10, lang= "en")
nba_tweets_text <- sapply(nba_tweets, function(x) x$getText())
str(nba_tweets_text)
nba_corpus <- Corpus(VectorSource(nba_tweets_text))
inspect(nba_corpus[1])
inspect(nba_corpus[66])
library(twitteR)
nba_tweets <- searchTwitter("NBA", n = 10, lang= "en")
consumerKey <- "eIaUSZ0CW1baBIawv6aO3yGhA"
consumerSecret <- "U8ceWsFc8lymqRtfhK1b1QQR1DFvDUPUORbBNkYy4ziOiOhk3a"
accessToken <- "978170993544806400-lb7cs4vPkCtbHqwCO6vynaMceKRs0Ig"
accessSecret <- "ewPYmyyGWce0ZgOpITkqJxJ8hVbKzkSZqecSG6Tjx6wD4"
setup_twitter_oauth(consumerKey, consumerSecret, accessToken, accessSecret)
nba_tweets <- searchTwitter("NBA", n = 10, lang= "en")
nba_tweets_text <- sapply(nba_tweets, function(x) x$getText())
str(nba_tweets_text)
nba_corpus <- Corpus(VectorSource(nba_tweets_text))
inspect(nba_corpus[1])
inspect(nba_corpus[66])
inspect(nba_corpus[5])
nba_corpus_clean <- tm_map(nba_corpus, removePunctuation)
nba_corpus_clean <- tm_map(nba_corpus_clean, content_transformer(tolower))
inspect(nba_corpus_clean[8])
inspect(nba_corpus_clean[3])
nba_corpus_clean[-3]
nba_corpus_clean <- tm_map(nba_corpus_clean, content_transformer(tolower))
nba_corpus_clean <-nba_corpus_clean[-3]
nba_corpus_clean <- tm_map(nba_corpus_clean, content_transformer(tolower))
nba_corpus_clean <- tm_map(nba_corpus_clean, removeWords, stopwords("english"))
inspect(nba_corpus_clean[5])
nba_corpus_clean <- tm_map(nba_corpus_clean, removeNumbers)
nba_corpus_clean <- tm_map(nba_corpus_clean, stripWhitespace)
nba_corpus_clean <- tm_map(nba_corpus_clean, removeWords, c("nba"))
wordcloud(nba_corpus_clean)
use warnings()
use warnings(nba_corpus_clean)
warnings()
nba_tweets <- searchTwitter("NBA", n = 100, lang= "en")
nba_tweets_text <- sapply(nba_tweets, function(x) x$getText())
str(nba_tweets_text)
nba_corpus <- Corpus(VectorSource(nba_tweets_text))
inspect(nba_corpus[1])
nba_corpus_clean <- tm_map(nba_corpus, removePunctuation)
nba_corpus_clean <- tm_map(nba_corpus_clean, content_transformer(tolower))
library(RCurl)
library(bitops)
library(twitteR)
library(tm)
library(NLP)
library(wordcloud)
library(RColorBrewer)
library(bitops)
library(RCurl)
library(twitteR)
library(NLP)
library(tm)
library(RColorBrewer)
library(wordcloud)
consumerKey <- "eIaUSZ0CW1baBIawv6aO3yGhA"
consumerSecret <- "U8ceWsFc8lymqRtfhK1b1QQR1DFvDUPUORbBNkYy4ziOiOhk3a"
accessToken <- "978170993544806400-lb7cs4vPkCtbHqwCO6vynaMceKRs0Ig"
accessSecret <- "ewPYmyyGWce0ZgOpITkqJxJ8hVbKzkSZqecSG6Tjx6wD4"
setup_twitter_oauth(consumerKey, consumerSecret, accessToken, accessSecret)
nba_tweets <- searchTwitter("NBA", n = 100, lang= "en")
nba_tweets_text <- sapply(nba_tweets, function(x) x$getText())
nba_corpus <- Corpus(VectorSource(nba_tweets_text))
nba_corpus_clean <- tm_map(nba_corpus, removePunctuation)
nba_corpus_clean <- tm_map(nba_corpus_clean, content_transformer(tolower))
Encoding(nba_corpus_clean) <- "UTF-8"
str(nba_tweets_text)
Encoding(nba_tweets_text) <- "UTF-8"
nba_corpus <- Corpus(VectorSource(nba_tweets_text))
nba_corpus_clean <- tm_map(nba_corpus, removePunctuation)
nba_corpus_clean <- tm_map(nba_corpus_clean, content_transformer(tolower))
str_conv(nba_tweets_text, "UTF-8")
install.packages("stringr")
library(stringr)
str_conv(nba_tweets_text, "UTF-8")
warnings()
nba_tweets_text[-1, -2 ,-3, -4 ,-5, -6 ,-7, -8, -9 ,10, -11,-12, -13, -14, -15,-16, -17, -18, -19, -20, -21, -22, -23, -24, -25, -26]
nba_tweets_text[-1]
nba_tweets_text <-nba_tweets_text[-1]
nba_tweets_text <-nba_tweets_text[-2]
nba_tweets_text <-nba_tweets_text[-3]
nba_tweets_text <-nba_tweets_text[-4]
nba_tweets_text <-nba_tweets_text[-5]
nba_tweets_text <-nba_tweets_text[-6]
nba_tweets_text <-nba_tweets_text[-7]
nba_tweets_text <-nba_tweets_text[-8]
nba_tweets_text <-nba_tweets_text[-9]
nba_tweets_text <-nba_tweets_text[-10]
nba_tweets_text <-nba_tweets_text[-11]
nba_tweets_text <-nba_tweets_text[-12]
nba_tweets_text <-nba_tweets_text[-13]
nba_tweets_text <-nba_tweets_text[-14]
nba_tweets_text <-nba_tweets_text[-15]
nba_tweets_text <-nba_tweets_text[-16]
nba_tweets_text <-nba_tweets_text[-17]
nba_tweets_text <-nba_tweets_text[-18]
nba_tweets_text <-nba_tweets_text[-19]
nba_tweets_text <-nba_tweets_text[-20]
nba_tweets_text <-nba_tweets_text[-21]
nba_tweets_text <-nba_tweets_text[-22]
nba_tweets_text <-nba_tweets_text[-23]
nba_tweets_text <-nba_tweets_text[-24]
nba_tweets_text <-nba_tweets_text[-25]
nba_tweets_text <-nba_tweets_text[-26]
nba_corpus <- Corpus(VectorSource(nba_tweets_text))
inspect(nba_corpus[1])
nba_corpus_clean <- tm_map(nba_corpus, removePunctuation)
nba_corpus_clean <- tm_map(nba_corpus_clean, content_transformer(tolower))
str_conv(nba_tweets_text, "UTF-8")
warnings()
nba_corpus_clean[-19]
nba_corpus_clean <- tm_map(nba_corpus_clean, content_transformer(tolower))
nba_corpus_clean <- nba_corpus_clean[-19]
nba_corpus_clean <- tm_map(nba_corpus_clean, content_transformer(tolower))
nba_corpus_clean <- nba_corpus_clean
nba_corpus_clean <- nba_corpus_clean[-19]
nba_corpus_clean <- nba_corpus_clean[-23]
nba_corpus_clean <- nba_corpus_clean[-24]
nba_corpus_clean <- nba_corpus_clean[-30]
nba_corpus_clean <- nba_corpus_clean[-45]
nba_corpus_clean <- nba_corpus_clean[-48]
nba_corpus_clean <- nba_corpus_clean[-58]
nba_corpus_clean <- nba_corpus_clean[-73]
nba_corpus_clean <- tm_map(nba_corpus_clean, content_transformer(tolower))
nba_corpus_clean
nba_corpus_clean <- nba_corpus_clean[-19]
nba_corpus_clean <- nba_corpus_clean[-23]
nba_corpus_clean <- nba_corpus_clean[-24]
nba_corpus_clean <- nba_corpus_clean[-30]
nba_corpus_clean <- nba_corpus_clean[-45]
nba_corpus_clean <- nba_corpus_clean[-48]
nba_corpus_clean <- nba_corpus_clean[-58]
nba_corpus_clean <- nba_corpus_clean[-73]
nba_corpus_clean <- tm_map(nba_corpus_clean, content_transformer(tolower))
nba_corpus_clean <- nba_corpus_clean[-23]
nba_corpus_clean <- tm_map(nba_corpus_clean, content_transformer(tolower))
nba_corpus_clean <- nba_corpus_clean[-23]
nba_corpus_clean[23]
View(nba_corpus_clean)
nba_corpus_clean <- tm_map(nba_corpus_clean, content_transformer(tolower))
nba_corpus_clean <- tm_map(nba_corpus_clean, removeWords, stopwords("english"))
nba_corpus_clean <- tm_map(nba_corpus_clean, removeNumbers)
nba_corpus_clean <- tm_map(nba_corpus_clean, stripWhitespace)
nba_corpus_clean <- tm_map(nba_corpus_clean, removeWords, c("nba"))
wordcloud(nba_corpus_clean)
nba_corpus_clean <- tm_map(nba_corpus_clean, removeWords, c("nba"))
wordcloud(nba_corpus_clean)
wordcloud(nba_corpus_clean)
Taiwan_tweets <- searchTwitter("Taiwan", n = 100, lang= "en")
Taiwan_tweets_text <- sapply(Taiwan_tweets, function(x) x$getText())
str(Taiwan_tweets_text)
str_conv(nba_tweets_text, "UTF-8")
Taiwan_corpus <- Corpus(VectorSource(Taiwan_tweets_text))
inspect(nba_corpus[1])
inspect(Taiwan_corpus [1])
Taiwan_corpus_clean <- tm_map(Taiwan_corpus, removePunctuation)
Taiwan_corpus_clean <- tm_map(Taiwan_corpus_clean, content_transformer(tolower))
Taiwan_corpus_clean <- tm_map(Taiwan_corpus_clean, removeWords, stopwords("english"))
Taiwan_corpus_clean <- tm_map(Taiwan_corpus_clean, removeNumbers)
Taiwan_corpus_clean <- tm_map(Taiwan_corpus_clean, stripWhitespace)
wordcloud(nba_corpus_clean)
wordcloud(Taiwan_corpus_clean)
Taiwan_corpus_clean <- tm_map(Taiwan_corpus_clean, removeWords, c("taiwan"))
wordcloud(Taiwan_corpus_clean)
wordcloud(Taiwan_corpus_clean)
wordcloud(Taiwan_corpus_clean)
wordcloud(Taiwan_corpus_clean)
library(RCurl)
nba_tweets <- searchTwitter("NBA", n = 1000, lang= "en")
nba_tweets_text <- sapply(nba_tweets, function(x) x$getText())
nba_corpus <- Corpus(VectorSource(nba_tweets_text))
nba_corpus_clean <- tm_map(nba_corpus, removePunctuation)
nba_corpus_clean <- tm_map(nba_corpus_clean, removeWords, stopwords("english"))
nba_corpus_clean <- tm_map(nba_corpus_clean, removeNumbers)
nba_corpus_clean <- tm_map(nba_corpus_clean, stripWhitespace)
nba_corpus_clean <- tm_map(nba_corpus_clean, removeWords, c("nba"))
wordcloud(nba_corpus_clean)
wordcloud(nba_corpus_clean, random.order = F, max.words = 40, scale = c(3, 0.5), colors = rainbow(50))
wordcloud(nba_corpus_clean, random.order = F, max.words = 40, scale = c(4, 0.5), colors = rainbow(50))
wordcloud(nba_corpus_clean, random.order = F, max.words = 40, scale = c(8, 0.5), colors = rainbow(50))
nba_corpus_clean <- tm_map(nba_corpus_clean, removeWords, c("nba"))
wordcloud(nba_corpus_clean, random.order = F, max.words = 40, scale = c(8, 0.5), colors = rainbow(50))
install.packages("gsub")
install.packages("grep")
nba_tweets_text <- gsub("\\\w+ *", " ", nba_tweets_text)
nba_tweets_text <- gsub("[\u{1F300}-\u{1F5FF}|\u{1F1E6}-\u{1F1FF}|\u{2700}-\u{27BF}|\u{1F900}-\u{1F9FF}|\u{1F600}-\u{1F64F}|\u{1F680}-\u{1F6FF}|\u{2600}-\u{26FF}] ", " ", nba_tweets_text)
gsub('\\p{So}|\\p{Cn}', '', nba_tweets, perl = TRUE)
gsub('\\p{So}|\\p{Cn}', '', nba_tweets_text, perl = TRUE)
nba_corpus <- Corpus(VectorSource(nba_tweets_text))
nba_corpus_clean <- tm_map(nba_corpus, removePunctuation)
nba_corpus_clean <- tm_map(nba_corpus_clean, content_transformer(tolower))
nba_corpus_clean <- tm_map(nba_corpus_clean, removeWords, stopwords("english"))
nba_corpus_clean <- tm_map(nba_corpus_clean, removeNumbers)
nba_corpus_clean <- tm_map(nba_corpus_clean, stripWhitespace)
nba_corpus_clean <- tm_map(nba_corpus_clean, removeWords, c("nba"))
wordcloud(nba_corpus_clean, random.order = F, max.words = 40, scale = c(8, 0.5), colors = rainbow(50))
grep("nba", nba_tweets_text)
grep("pts", nba_tweets_text)
gsub('\u', ' ', nba_tweets_text, perl = TRUE)
gsub('\\u', ' ', nba_tweets_text, perl = TRUE)
gsub('\\\u', ' ', nba_tweets_text, perl = TRUE)
gsub('\\u{1F300}', ' ', nba_tweets_text, perl = TRUE)
gsub('\\u{1F300}', ' ', nba_tweets_text)
grep("\u{1F300}", nba_tweets_text)
nba_corpus_clean <- tm_map(nba_corpus_clean, toSpace ,"\u")
nba_corpus_clean <- tm_map(nba_corpus_clean, toSpace ,"\n")
nba_corpus_clean <- tm_map(nba_corpus_clean, toSpace ,"nba")
library(tm)
library(NLP)
library(tm)
nba_corpus_clean <- tm_map(nba_corpus_clean, toSpace ,"nba")
library(httr)
library(rjson)
library(httpuv)
library(Rfacebook)
library(plyr)
library(NLP)
library(tm)
library(rvest)
library(xml2)
library(rvest)
library(rJava)
library(SnowballC)
library(slam)
library(Matrix)
install.packages("rJava")
install.packages("SnowballC")
library(rJava)
library(SnowballC)
library(RCurl)
library(RCurl)
library(bitops)
library(RCurl)
library(twitteR)
library(tm)
library(NLP)
library(tm)
library(wordcloud)
library(RColorBrewer)
library(wordcloud)
library(textclean)
consumerKey <- "eIaUSZ0CW1baBIawv6aO3yGhA"
consumerSecret <- "U8ceWsFc8lymqRtfhK1b1QQR1DFvDUPUORbBNkYy4ziOiOhk3a"
accessToken <- "978170993544806400-lb7cs4vPkCtbHqwCO6vynaMceKRs0Ig"
accessSecret <- "ewPYmyyGWce0ZgOpITkqJxJ8hVbKzkSZqecSG6Tjx6wD4"
consumerKey <- "eIaUSZ0CW1baBIawv6aO3yGhA"
consumerSecret <- "U8ceWsFc8lymqRtfhK1b1QQR1DFvDUPUORbBNkYy4ziOiOhk3a"
accessToken <- "978170993544806400-lb7cs4vPkCtbHqwCO6vynaMceKRs0Ig"
accessSecret <- "ewPYmyyGWce0ZgOpITkqJxJ8hVbKzkSZqecSG6Tjx6wD4"
setup_twitter_oauth(consumerKey, consumerSecret, accessToken, accessSecret)
nba_tweets <- searchTwitter("NBA", n = 1000, lang= "en")
nba_tweets_text <- sapply(nba_tweets, function(x) x$getText())
replace_emoji(nba_tweets_text)
for(i in seq(nba_tweets_text)){
nba_tweets_text[[i]]<-gsub('[[:punct:]]', '', nba_tweets_text[[i]])
nba_tweets_text[[i]]<-gsub("，"," ", nba_tweets_text[[i]])
nba_tweets_text[[i]]<-gsub("-"," ", nba_tweets_text[[i]])
nba_tweets_text[[i]]<-gsub("U+1F525"," ", nba_tweets_text[[i]])
}
nba_corpus <- Corpus(VectorSource(nba_tweets_text))
toSpace <- content_transformer(function(x, pattern) {
return (gsub(pattern, " ", x))}
)
nba_corpus_clean <- tm_map(nba_corpus, removePunctuation)
for(i in seq(nba_corpus_clean)){
nba_corpus_clean[[i]]<-gsub('[[:punct:]]', '', nba_corpus_clean[[i]])
nba_corpus_clean[[i]]<-gsub("，"," ", nba_corpus_clean[[i]])
nba_corpus_clean[[i]]<-gsub("-"," ", nba_corpus_clean[[i]])
nba_corpus_clean[[i]]<-gsub("U+1F525"," ", nba_corpus_clean[[i]])
}
nba_corpus_clean <- tm_map(nba_corpus_clean, content_transformer(tolower))
nba_corpus_clean <- tm_map(nba_corpus, removePunctuation)
nba_corpus_clean <- tm_map(nba_corpus_clean, content_transformer(tolower))
nba_corpus_clean <- tm_map(nba_corpus, removePunctuation)
nba_corpus_clean <- tm_map(nba_corpus_clean, removeWords, stopwords("english"))
nba_corpus_clean <- tm_map(nba_corpus_clean, removeNumbers)
nba_corpus_clean <- tm_map(nba_corpus_clean, stripWhitespace)
nba_corpus_clean <- tm_map(nba_corpus_clean, removeWords, "nba")
nba_corpus_clean <- tm_map(nba_corpus_clean, toSpace, "nba")
wordcloud(nba_corpus_clean)
wordcloud(nba_corpus_clean, random.order = F, max.words = 40, scale = c(8, 0.5), colors = rainbow(50))
wordcloud(nba_corpus_clean, random.order = F, max.words = 40, scale = c(8, 0.5), colors = rainbow(50))
install.packages("rJava")
install.packages("Rwordseg", repos="http://R-Forge.R-project.org")
install.packages("tm")
install.packages("tmcn", repos="http://R-Forge.R-project.org", type="source")
install.packages("tm")
install.packages("tm")
install.packages("tm")
findprime  <- function(x) {
if (x %in% c(2,3,5,7)) return(TRUE)
if (x%%2 == 0 | x==1) return(FALSE)
xsqrt <- round(sqrt(x))
xseq <- seq(from=3,to=xsqrt,by=2)
if (all(x %% xseq !=0)) return(TRUE)
else return(FALSE)
}
x = 1:150
i <- x[sapply(x,findprime)]
print (iris$Petal.Width[i])
for(i in 1:nrow(iris)){
if (i==2) {
print (i)}
else if(i>2){
if (all(i%%(2:(i-1))!=0)){
print(i)}}}
for(i in 1:nrow(iris)){
if (i==2) {
print ((iris$Petal.Width[i])}
else if(i>2){
if (all(i%%(2:(i-1))!=0)){
print((iris$Petal.Width[i])}}}
for(i in 1:150){
if (i==2) {
print ((iris$Petal.Width[i])}
else if(i>2){
if (all(i%%(2:(i-1))!=0)){
print((iris$Petal.Width[i])}}}
for(i in 1:150){
if (i==2) {
print ((iris[i])}
else if(i>2){
if (all(i%%(2:(i-1))!=0)){
print((iris[i])}}}
for(i in 1:150){
if (i==2) {
print (i)}
else if(i>2){
if (all(i%%(2:(i-1))!=0)){
print(i)}}}
nrow(iris)
for(i in 1:nrow(iris)){
if (i==2) {
print (iris[i])}
else if(i>2){
if (all(i%%(2:(i-1))!=0)){
print(iris[i])}}}
for(i in 1:nrow(iris)){
if (i==2) {
print (iris$Petal.Width[i])}
else if(i>2){
if (all(i%%(2:(i-1))!=0)){
print(iris$Petal.Width[i])}}}
library(tm)
install.packages(tm)
library(tm)
install.packages("tm")
install.packages("tm")
findprime  <- function(x) {
if (x %in% c(2,3,5,7)) return(TRUE)
if (x%%2 == 0 | x==1) return(FALSE)
xsqrt <- round(sqrt(x))
xseq <- seq(from=3,to=xsqrt,by=2)
if (all(x %% xseq !=0)) return(TRUE)
else return(FALSE)
}
function(10)
x = 1:10
x[sapply(x,findprime)]
findprime  <- function(x) {
if (x%%2 == 0 | x==1) return(FALSE)
xsqrt <- round(sqrt(x))
xseq <- seq(from=3,to=xsqrt,by=2)
if (all(x %% xseq !=0)) return(TRUE)
else return(FALSE)
}
x = 1:10
x[sapply(x,findprime)]
findprime  <- function(x) {
if (x %in% c(2,3,5)) return(TRUE)
if (x%%2 == 0 | x==1) return(FALSE)
xsqrt <- round(sqrt(x))
xseq <- seq(from=3,to=xsqrt,by=2)
if (all(x %% xseq !=0)) return(TRUE)
else return(FALSE)
}
x = 1:10
x[sapply(x,findprime)]
findprime  <- function(x) {
if (x %in% c(2,3,5)) return(TRUE)
if (x%%2 == 0 | x==1) return(FALSE)
xsqrt <- round(sqrt(x))
xseq <- seq(from=3,to=xsqrt,by=2)
if (all(x %% xseq !=0)) return(TRUE)
else return(FALSE)
}
x = 1:10
x[sapply(x,findprime)]
findprime  <- function(x) {
if (x %in% c(2,3)) return(TRUE)
if (x%%2 == 0 | x==1) return(FALSE)
xsqrt <- round(sqrt(x))
xseq <- seq(from=3,to=xsqrt,by=2)
if (all(x %% xseq !=0)) return(TRUE)
else return(FALSE)
}
x = 1:10
x[sapply(x,findprime)]
install.packages("tm")
library(tm)
library(NLP)
library(NLP)
library(tm)
d.corpus <- Corpus(DirSource("b"), list(language = NA))
rm(d.corpus)
d.corpus <- Corpus(DirSource("b"), list(language = NA))
