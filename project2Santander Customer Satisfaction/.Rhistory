data <- list()
for (id in c(from:to))
{
url <- paste0(prefix, as.character(id), ".html" )
html<- htmlParse(GET(url))
url.list <- xpathSApply(html, "//div[@class='title']/a[@href]", xmlAttrs)
data <- rbind(data, as.matrix(paste("www.ptt.cc", url.list, sep='')))
title <- rbind(title, as.matrix(title.list))
}
from <- 485
to   <- 501
prefix = "https://www.ptt.cc/bbs/TW_Entertain/index"
data <- list()
for (id in c(from:to))
{
url <- paste0(prefix, as.character(id), ".html" )
html<- htmlParse(GET(url))
url.list <- xpathSApply(html, "//div[@class='title']/a[@href]", xmlAttrs)
data <- rbind(data, as.matrix(paste("www.ptt.cc", url.list, sep='')))
}
data <- unlist(data)
head(data)
from <- 485
to   <- 501
prefix = "https://www.ptt.cc/bbs/TW_Entertain/index"
data <- list()
title <- list()
for (id in c(from:to))
{
url <- paste0(prefix, as.character(id), ".html" )
html<- htmlParse(GET(url))
url.list <- xpathSApply(html, "//div[@class='title']/a[@href]", xmlAttrs)
title.list <- xpathSApply(html, "//div[@class='title']/a[@href]", xmlValue)
data <- rbind(data, as.matrix(paste("www.ptt.cc", url.list, sep='')))
title <- rbind(title, as.matrix(title.list))
}
data <- unlist(data)
title <- unlist(title)
head(data)
head(title)
Hito <- c()
Hito.url <- c()
HitoT <- grep("綜藝大熱門", title)
Hito <- title[HitoT]
Hito.url <- data[HitoT]
SB <- c()
SB.url <- c()
SBT <- grep("小明星大跟班", title)
SB <- title[SBT]
SB.url <- data[SBT]
Hito <- c()
Hito.url <- c()
HitoT <- grep("綜藝大熱門", title)
Hito <- c(Hito,title[HitoT])
Hito.url <- c(Hito.url, data[HitoT])
SB <- c()
SB.url <- c()
SBT <- grep("小明星大跟班", title)
SB <- c(SB,title[SBT])
SB.url <- c(SB.url, data[SBT])
message <- list()
cc = worker()
HitoTDF <- data.frame()
SBTDF <- data.frame()
for(i in c(1:length(Hito))){
html <- htmlParse(GET(Hito.url[i]),encoding = "UTF-8")
message.list <- xpathSApply(html, "//div[@class='push']/span[@class='f3 push-content']", xmlValue)
message <- unlist(message.list)
d.corpus <- VCorpus( VectorSource(message) )
d.corpus <- tm_map(d.corpus, removePunctuation)
d.corpus <- tm_map(d.corpus, removeNumbers)
d.corpus <- tm_map(d.corpus, function(word) {
gsub("[A-Za-z0-9]", "", word)
})
abc <- data.frame(table(cc[as.character(d.corpus)]))
colnames(abc) <- c("word", as.character(i))
if(i == 1){
HitoTDF <- abc}
else{
HitoTDF <- merge(HitoTDF, abc, by = "word", all = T)}
}
for(i in c(1:length(SB))){
html <- htmlParse(GET(Hito.url[i]),encoding = "UTF-8")
message.list <- xpathSApply(html, "//div[@class='push']/span[@class='f3 push-content']", xmlValue)
message <- unlist(message.list)
d.corpus <- VCorpus( VectorSource(message) )
d.corpus <- tm_map(d.corpus, removePunctuation)
d.corpus <- tm_map(d.corpus, removeNumbers)
d.corpus <- tm_map(d.corpus, function(word) {
gsub("[A-Za-z0-9]", "", word)
})
abc <- data.frame(table(cc[as.character(d.corpus)]))
colnames(abc) <- c("word", as.character(i))
if(i == 1){
SBTDF <- abc}
else{
SBTDF <- merge(HitoTDF, abc, by = "word", all = T)}
}
message <- list()
cc = worker()
HitoTDF <- data.frame()
SBTDF <- data.frame()
for(i in c(1:length(Hito))){
html <- htmlParse(GET(Hito.url[i]),encoding = "UTF-8")
message.list <- xpathSApply(html, "//div[@class='push']/span[@class='f3 push-content']", xmlValue)
message <- unlist(message.list)
d.corpus <- VCorpus( VectorSource(message) )
d.corpus <- tm_map(d.corpus, removePunctuation)
d.corpus <- tm_map(d.corpus, removeNumbers)
d.corpus <- tm_map(d.corpus, function(word) {
gsub("[A-Za-z0-9]", "", word)
})
abc <- data.frame(table(cc[as.character(d.corpus)]))
colnames(abc) <- c("word", as.character(i))
if(i == 1){
HitoTDF <- abc}
else{
HitoTDF <- merge(HitoTDF, abc, by = "word", all = T)}
}
for(i in c(1:length(SB))){
html <- htmlParse(GET(Hito.url[i]),encoding = "UTF-8")
message.list <- xpathSApply(html, "//div[@class='push']/span[@class='f3 push-content']", xmlValue)
message <- unlist(message.list)
d.corpus <- VCorpus( VectorSource(message) )
d.corpus <- tm_map(d.corpus, removePunctuation)
d.corpus <- tm_map(d.corpus, removeNumbers)
d.corpus <- tm_map(d.corpus, function(word) {
gsub("[A-Za-z0-9]", "", word)
})
abc <- data.frame(table(cc[as.character(d.corpus)]))
colnames(abc) <- c("word", as.character(i))
if(i == 1){
SBTDF <- abc}
else{
SBTDF <- merge(HitoTDF, abc, by = "word", all = T)}
}
message <- list()
HitoTDF <- data.frame()
SBTDF <- data.frame()
for(i in c(1:length(Hito))){
html <- htmlParse(GET(Hito.url[i]),encoding = "UTF-8")
message.list <- xpathSApply(html, "//div[@class='push']/span[@class='f3 push-content']", xmlValue)
message <- unlist(message.list)
d.corpus <- VCorpus( VectorSource(message) )
d.corpus <- tm_map(d.corpus, removePunctuation)
d.corpus <- tm_map(d.corpus, removeNumbers)
d.corpus <- tm_map(d.corpus, function(word) {
gsub("[A-Za-z0-9]", "", word)
})
abc <- data.frame(table(cc[as.character(d.corpus)]))
colnames(abc) <- c("word", as.character(i))
if(i == 1){
HitoTDF <- abc}
else{
HitoTDF <- merge(HitoTDF, abc, by = "word", all = T)}
}
for(i in c(1:length(SB))){
html <- htmlParse(GET(SB.url[i]),encoding = "UTF-8")
message.list <- xpathSApply(html, "//div[@class='push']/span[@class='f3 push-content']", xmlValue)
message <- unlist(message.list)
d.corpus <- VCorpus( VectorSource(message) )
d.corpus <- tm_map(d.corpus, removePunctuation)
d.corpus <- tm_map(d.corpus, removeNumbers)
d.corpus <- tm_map(d.corpus, function(word) {
gsub("[A-Za-z0-9]", "", word)
})
abc <- data.frame(table(cc[as.character(d.corpus)]))
colnames(abc) <- c("word", as.character(i))
if(i == 1){
SBTDF <- abc}
else{
SBTDF <- merge(HitoTDF, abc, by = "word", all = T)}
}
LBJTDF[is.na(LBJTDF)] <- 0
HitoTDF[is.na(HitoTDF)] <- 0
SBTDF[is.na(SBTDF)] <- 0
library(knitr)
kable(head(HitoTDF))
kable(head(SBTDF))
kable(tail(HitoTDF))
kable(tail(SBTDF))
kable(head(SBTDF))
kable(head(HitoTDF))
kable(head(HitoTDF))
kable(tail(HitoTDF))
kable(head(SBTDF))
kable(tail(SBTDF))
n <- length(Hito)
tf1 <- apply(as.matrix(HitoTDF[,2:(n+1)]), 2, sum)
library(Matrix)
idfCal1 <- function(word_doc)
{
log2( n / nnzero(word_doc) )
}
idf1 <- apply(as.matrix(HitoTDF[,2:(n+1)]), 1, idfCal1)
doc1.tfidf <- HitoTDF
for(x in 1:nrow(HitoTDF))
{
for(y in 2:ncol(HitoTDF))
{
doc1.tfidf[x,y] <- (doc1.tfidf[x,y] / tf1[y-1]) * idf1[x]
}
}
n <- length(SB)
tf2 <- apply(as.matrix(SBTDF[,2:(n+1)]), 2, sum)
n <- length(Hito)
tf1 <- apply(as.matrix(HitoTDF[,2:(n+1)]), 2, sum)
library(Matrix)
idfCal1 <- function(word_doc)
{
log2( n / nnzero(word_doc) )
}
idf1 <- apply(as.matrix(HitoTDF[,2:(n+1)]), 1, idfCal1)
doc1.tfidf <- HitoTDF
for(x in 1:nrow(HitoTDF))
{
for(y in 2:ncol(HitoTDF))
{
doc1.tfidf[x,y] <- (doc1.tfidf[x,y] / tf1[y-1]) * idf1[x]
}
}
n <- length(SB)
tf2 <- apply(as.matrix(SBTDF[,2:(n+1)]), 2, sum)
m <- length(SB)
tf2 <- apply(as.matrix(SBTDF[,2:(m+1)]), 2, sum)
library(Matrix)
m <- length(SB)
tf2 <- apply(as.matrix(SBTDF[,2:(m+1)]), 2, sum)
View(SBTDF)
View(HitoTDF)
library(bitops)
library(httr)
library(RCurl)
library(XML)
library(NLP)
library(tm)
library(tmcn)
library(jiebaRD)
library(jiebaR)
library(dplyr)
Hito <- c()
Hito.url <- c()
HitoT <- grep("綜藝大熱門", title)
Hito <- c(Hito,title[HitoT])
Hito.url <- c(Hito.url, data[HitoT])
SB <- c()
SB.url <- c()
SBT <- grep("小明星大跟班", title)
SB <- c(SB,title[SBT])
SB.url <- c(SB.url, data[SBT])
message <- list()
HitoTDF <- data.frame()
SBTDF <- data.frame()
for(i in c(1:length(Hito))){
html <- htmlParse(GET(Hito.url[i]),encoding = "UTF-8")
message.list <- xpathSApply(html, "//div[@class='push']/span[@class='f3 push-content']", xmlValue)
message <- unlist(message.list)
d.corpus <- VCorpus( VectorSource(message) )
d.corpus <- tm_map(d.corpus, removePunctuation)
d.corpus <- tm_map(d.corpus, removeNumbers)
d.corpus <- tm_map(d.corpus, function(word) {
gsub("[A-Za-z0-9]", "", word)
})
abc <- data.frame(table(cc[as.character(d.corpus)]))
colnames(abc) <- c("word", as.character(i))
if(i == 1){
HitoTDF <- abc}
else{
HitoTDF <- merge(HitoTDF, abc, by = "word", all = T)}
}
library(jiebaR)
message <- list()
HitoTDF <- data.frame()
SBTDF <- data.frame()
for(i in c(1:length(Hito))){
html <- htmlParse(GET(Hito.url[i]),encoding = "UTF-8")
message.list <- xpathSApply(html, "//div[@class='push']/span[@class='f3 push-content']", xmlValue)
message <- unlist(message.list)
d.corpus <- VCorpus( VectorSource(message) )
d.corpus <- tm_map(d.corpus, removePunctuation)
d.corpus <- tm_map(d.corpus, removeNumbers)
d.corpus <- tm_map(d.corpus, function(word) {
gsub("[A-Za-z0-9]", "", word)
})
abc <- data.frame(table(cc[as.character(d.corpus)]))
colnames(abc) <- c("word", as.character(i))
if(i == 1){
HitoTDF <- abc}
else{
HitoTDF <- merge(HitoTDF, abc, by = "word", all = T)}
}
library(jiebaR)
message <- list()
HitoTDF <- data.frame()
SBTDF <- data.frame()
for(i in c(1:length(Hito))){
html <- htmlParse(GET(Hito.url[i]),encoding = "UTF-8")
message.list <- xpathSApply(html, "//div[@class='push']/span[@class='f3 push-content']", xmlValue)
message <- unlist(message.list)
d.corpus <- VCorpus( VectorSource(message) )
d.corpus <- tm_map(d.corpus, removePunctuation)
d.corpus <- tm_map(d.corpus, removeNumbers)
d.corpus <- tm_map(d.corpus, function(word) {
gsub("[A-Za-z0-9]", "", word)
})
abc <- data.frame(table(cc[as.character(d.corpus)]))
colnames(abc) <- c("word", as.character(i))
if(i == 1){
HitoTDF <- abc}
else{
HitoTDF <- merge(HitoTDF, abc, by = "word", all = T)}
}
for(i in c(1:length(SB))){
html <- htmlParse(GET(SB.url[i]),encoding = "UTF-8")
message.list <- xpathSApply(html, "//div[@class='push']/span[@class='f3 push-content']", xmlValue)
message <- unlist(message.list)
d.corpus <- VCorpus( VectorSource(message) )
d.corpus <- tm_map(d.corpus, removePunctuation)
d.corpus <- tm_map(d.corpus, removeNumbers)
d.corpus <- tm_map(d.corpus, function(word) {
gsub("[A-Za-z0-9]", "", word)
})
abc <- data.frame(table(cc[as.character(d.corpus)]))
colnames(abc) <- c("word", as.character(i))
if(i == 1){
SBTDF <- abc}
else{
SBTDF <- merge(HitoTDF, abc, by = "word", all = T)}
}
install.packages("jiebaR")
install.packages("jiebaR")
library(jiebaR)
library(jiebaRD)
library(jiebaR)
message <- list()
HitoTDF <- data.frame()
SBTDF <- data.frame()
for(i in c(1:length(Hito))){
html <- htmlParse(GET(Hito.url[i]),encoding = "UTF-8")
message.list <- xpathSApply(html, "//div[@class='push']/span[@class='f3 push-content']", xmlValue)
message <- unlist(message.list)
d.corpus <- VCorpus( VectorSource(message) )
d.corpus <- tm_map(d.corpus, removePunctuation)
d.corpus <- tm_map(d.corpus, removeNumbers)
d.corpus <- tm_map(d.corpus, function(word) {
gsub("[A-Za-z0-9]", "", word)
})
abc <- data.frame(table(cc[as.character(d.corpus)]))
colnames(abc) <- c("word", as.character(i))
if(i == 1){
HitoTDF <- abc}
else{
HitoTDF <- merge(HitoTDF, abc, by = "word", all = T)}
}
library(bitops)
library(httr)
library(RCurl)
library(XML)
library(NLP)
library(tm)
library(tmcn)
library(jiebaRD)
library(jiebaR)
library(dplyr)
from <- 485
to   <- 501
prefix = "https://www.ptt.cc/bbs/TW_Entertain/index"
data <- list()
title <- list()
for (id in c(from:to))
{
url <- paste0(prefix, as.character(id), ".html" )
html<- htmlParse(GET(url))
url.list <- xpathSApply(html, "//div[@class='title']/a[@href]", xmlAttrs)
title.list <- xpathSApply(html, "//div[@class='title']/a[@href]", xmlValue)
data <- rbind(data, as.matrix(paste("www.ptt.cc", url.list, sep='')))
title <- rbind(title, as.matrix(title.list))
}
data <- unlist(data)
title <- unlist(title)
head(data)
head(title)
Hito <- c()
Hito.url <- c()
HitoT <- grep("綜藝大熱門", title)
Hito <- c(Hito,title[HitoT])
Hito.url <- c(Hito.url, data[HitoT])
SB <- c()
SB.url <- c()
SBT <- grep("小明星大跟班", title)
SB <- c(SB,title[SBT])
SB.url <- c(SB.url, data[SBT])
message <- list()
HitoTDF <- data.frame()
SBTDF <- data.frame()
for(i in c(1:length(Hito))){
html <- htmlParse(GET(Hito.url[i]),encoding = "UTF-8")
message.list <- xpathSApply(html, "//div[@class='push']/span[@class='f3 push-content']", xmlValue)
message <- unlist(message.list)
d.corpus <- VCorpus( VectorSource(message) )
d.corpus <- tm_map(d.corpus, removePunctuation)
d.corpus <- tm_map(d.corpus, removeNumbers)
d.corpus <- tm_map(d.corpus, function(word) {
gsub("[A-Za-z0-9]", "", word)
})
abc <- data.frame(table(cc[as.character(d.corpus)]))
colnames(abc) <- c("word", as.character(i))
if(i == 1){
HitoTDF <- abc}
else{
HitoTDF <- merge(HitoTDF, abc, by = "word", all = T)}
}
pr <- predict(model, test,  OOB=TRUE, type = "response")
install.packages("xgboost")
library(xgboost)
library(Matrix)
set.seed(1234)
train <- read.csv("train.csv")
test  <- read.csv("test.csv")
setwd("C:/Users/User/Desktop/R/R/project2－Santander Customer Satisfaction")
train <- read.csv("train.csv")
test  <- read.csv("test.csv")
train$ID <- NULL
test.id <- test$ID
test$ID <- NULL
maxmin <- data.frame()
i <- 1
for(c in (names(train))){
maxmin[i,1] <- min(train[train$TARGET==1,c])
maxmin[i,2] <- max(train[train$TARGET==1,c])
i=i+1
}
row.names(maxmin) <- names(train)
names(maxmin) <- c('min', 'max')
View(maxmin)
train.y <- train$TARGET
train$TARGET <- NULL
count0 <- function(x) {
return( sum(x == 0) )
}
train$n0 <- apply(train, 1, FUN=count0)
test$n0 <- apply(test, 1, FUN=count0)
cat("\n## Removing the constants features.\n")
for (f in names(train)) {
if (length(unique(train[[f]])) == 1) {
cat(f, "is constant in train. We delete it.\n")
train[[f]] <- NULL
test[[f]] <- NULL
}
}
features_pair <- combn(names(train), 2, simplify = F)
toRemove <- c()
for(pair in features_pair) {
f1 <- pair[1]
f2 <- pair[2]
if (!(f1 %in% toRemove) & !(f2 %in% toRemove)) {
if (all(train[[f1]] == train[[f2]])) {
cat(f1, "and", f2, "are equals.\n")
toRemove <- c(toRemove, f2)
}
}
}
feature.names <- setdiff(names(train), toRemove)
train$var38 <- log(train$var38)
test$var38 <- log(test$var38)
maxmin['var38', 'min'] <- log(maxmin['var38', 'min'])
maxmin['var38', 'max'] <- log(maxmin['var38', 'max'])
train <- train[, feature.names]
test <- test[, feature.names]
#---limit vars in test based on min and max vals of train
print('Setting min-max lims on test data')
for(f in colnames(train)){
lim <- min(train[,f])
test[test[,f]<lim,f] <- lim
lim <- max(train[,f])
test[test[,f]>lim,f] <- lim
}
#---
train$TARGET <- train.y
train <- sparse.model.matrix(TARGET ~ ., data = train)
dtrain <- xgb.DMatrix(data=train, label=train.y)
watchlist <- list(train=dtrain)
param <- list(  objective           = "binary:logistic",
booster             = "gbtree",
eval_metric         = "auc",
eta                 = 0.0202048,
max_depth           = 5,
subsample           = 0.6815,
colsample_bytree    = 0.701
)
clf <- xgb.train(   params              = param,
data                = dtrain,
nrounds             = 560,
verbose             = 1,
watchlist           = watchlist,
maximize            = FALSE
)
test$TARGET <- -1
test_cp <- test
test_cp$TARGET <- NULL
test_cp$n0 <- NULL
test <- sparse.model.matrix(TARGET ~ ., data = test)
preds <- predict(clf, test)
### Frequentist cut
for(c in names(test_cp)){
preds[test_cp[c] < maxmin[c, 'min']] = 0.0001
preds[test_cp[c] > maxmin[c, 'max']] = 0.0001
}
### Submission
submission <- data.frame(ID=test.id, TARGET=preds)
cat("saving the submission file\n")
write.csv(submission, "submission.csv", row.names = F)
