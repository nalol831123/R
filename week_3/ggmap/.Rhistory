lvr_land <- read.table(lvr_land.path, header = TRUE, sep=",")
l10n_info()
read.table(textConnection(lvr_land.txt), header = TRUE, sep = ",")
bye()
library(swirl)
swirl()
bye()
swirl()
readBin(hospital_path)
readBin(hospital_path, what = "raw")
readBin(hospital_path, "raw", n = 3L)
readLines(file(hospital_path, encoding = "UTF-8"), n = 6)
readLines(file(hospital_path, encoding = "BIG5"), n = 6)
hospital <- read.table(file=hospital_path, encoding="BIG5", header = TRUE, sep = ",")
hospital$YEARYY
?substring
substring(head(hospital$YEARYY), 1, 3)
?strsplit
yearyy <- as.character(hospital$YEARYY)
tmp <- strsplit(yearyy, "Q")
hea(tmp)
head(tmp)
temp[[1]][1]
tmp[[1]][1]
length(tmp)
?lapply
lapply(tmp, "[", 1)
lapply(tmp, "[", 2)
tmp2 <- lapply(tmp, "[", 1)
unlist(tmp2)
sapply(tmp, "[", 1)
skip()
skip()
library(swirl)
swirl()
library(xml2)
install.packages("xml2")
library(xml2)
x1
?read_xml
doc1 <- read_xml(x1)
doc1
attributes(doc1)
class(doc1)
?xml_find_all
xml_find_all(doc1, "/a/b")
ml_find_all(doc1, "/b")
xml_find_all(doc1, "/b")
ns <- xml_find_all(doc1, "/a/c")
class(ns)
n1 <- ns[[1]]
xml_text(n1)
xml_parent(n1)
n2 <- ns[[2]]
xml_text(n2)
a <- xml_find_one(doc1, "/a")
xml_text(a)
xml_contents(a)
xml_children(a)
xml_attrs(n1)
xml_attrs(n2)
xml_find_all(doc1,"/a/c[@class]")
xml_find_all(doc1, "/a/c[@class='g']")
library(swirl)
swirl()
cat(facebook_error, sep = "\n")
install.packages(jsonlite)
library(jsonlite)
vignette(package = "jsonlite")
vignette("json-aaquickstart","jsonlite")
fromJSON(x1, simplifyVector = FALSE)
fromJSON(x1)
youbike1
youbike_path
youbike1 <- fromJSON(youbike_path)
youbike1 <- fromJSON(youbike_path)
View(youbike1)
skip()
library(swirl)
swirl()
bye()
library(swirl)
swirl()
install.packages(RSQLite)
install.packages("RSQLite")
library(RSQLite)
drv <- dbDriver("SQLite")
db <- dbConnect(drv, db_path)
?dbWriteTable
help.search("dbWriteTable")
help("dbWriteTable,SQLiteConnection,character,data.frame-method")
head(lvr_land)
dbWriteTable(db, "lvr_land2", lvr_land)
dbReadTable(db, "lvr_land2")
dbWriteTable(db, "lvr_land2", lvr_land, append = TRUE)
dbReadTable(db, "lvr_land2")
dbListTables(db)
iris2 <- dbReadTable(db, "iris")
all.equal(iris, iris2)
dbGetQuery(db, "SELECT * FROM iris WHERE species = \"virginica\"")
dbSendQuery(db, "SELECT * FROM iris")
rs <- dbSendQuery(db, "SELECT * FROM iris")
fetch(rs, 1)
fetch(rs, 1)
dbClearResult(rs)
dbDisconnect(db)
db <- dbConnect(drv, db_path)
dbBegin(db)
dbRemoveTable(db, "CO2")
dbListTables(db)
dbDisconnect(db)
db <- dbConnect(drv, db_path)
dbListTables(db)
dbBegin(db)
dbRemoveTable(db, "CO2")
dbCommit(db)
dbListTables(db)
library(swirl)
swirl()
install.packages("dplyr")
library(dplyr)
vignette(package = "dplyr")
vignette("introduction", package = "dplyr")
install.packages("nycflight13")
install.packages("nycflights13")
library(nycflights13)
length(nycflights13)
nycflights13
length(flights)
nrow(flights)
filter(flights, month == 1, day == 1)
skip()
`flights[flights$month == 1 & flights$day == 2,]
local(flights[flights$month == 1 & flights$day == 2,])
filter(flights, month == 1 | month == 2)
0
c
flights
skip()
filter(flights, month == 1 | month == 2)
bye()
\\
//
/
//
end
end()
filter(flights, month == 1 | month == 2)
filter(flights, month == 1 | month == 2)
submit()
# local函數只會輸出最後一個expression的結果
# 所以中間建立的變數不會污染到外部
answer02 <- local({
# 提示：先拿flights$month 和 1 比較
month_is_1 <- flights$month == 1
# 再拿flights$day 和 1 比較
day_is_2 <- flights$day == 2
# 拿上面兩個比較結果做 & 後丟到中括號的第一個參數。
is_target <- month_is_1 & day_is_2
flights[is_target,]
})
answer02
library(swirl)
swirl()
filter(flights, month == 1 | month == 2)
flights
library(nycflights13)
filter(flights, month == 1, day == 2)
filter(flights, month == 1 | month == 2)
filter(flights, month == 1, day == 2)
skip()
swirl()
install.packages("dplyr")
library(dplyr)
vignette(package = "dplyr")
vignette("introduction", package = "dplyr")
install.packages("nycflights13")
install.packages("nycflights13")
library(nycflights13)
library(nycflights13)
library(nycflights13)
library(swirl)
swirl()
install.packages(dplyr)
library(dplyr)
vignette(package = "dplyr")
vignette("introduction", package = "dplyr")
install.packages("nycflights13")
library(nycflights13)
nrow(flights)
filter(flights, month == 1, day == 1)
submit()
submit()
skup()
skip()
filter(flights, month==1 , month==2)
filter(flights, month == 1, day == 2)
submit()
submit()
skip()
?grepl
filter(flights, grepl(pattern = "AA", x = tailnum, fixed = TRUE))
slice(flights, 10000:20000)
arrange(flights, month, day, dep_time)
min(flights$dep_time)
min(flights$dep_time, na.rm = TRUE)
arrange(flights, desc(month), desc(day), desc(dep_time))
select(flights, year, month, day)
rownames(flights)
colnames(flights)
select(flights, year:day)
select(flights, -(year:day))
submit()
skip()
distinct(select(flights, year:day))
mutate(flights, gain = arr_delay - dep_delay)
summarise(flights, mean(dep_delay, na.rm = TRUE))
sample_n(flights, 10)
sample_frac(flights, 0.01)
()
skip()
submit()
submit()
skip()
submit()
submit()
submiy()
submit()
submit()
submit()
skip()
skip()
skip()
submit()
library(swirl)
rm(list=ls())
swirl()
skip()
library(dplyr)
vignette("two-table", package = "dplyr")
skip()
library(nycflights13)
View(airlines)
slice(flights, 1)
?left_join
skip()
View(weather)
answer02 <- left_join(answer01, weather)
View(answer02)
intersect(colnames(answer01), colnames(weather))
View(airports)
c("origin" = "faa")
answer03 <-left_join(answer02, airports, by = c("origin" = "faa"))
View(answer03)
answer04 <- left_join(answer03$dest, airports$faa)
answer04 <- left_join(answer03$dest, airports$faa, by = c("origin" = "faa"))
answer04 <- left_join(answer03, airports, by = c("dest" = "faa"))
colnames(answer04)
submit()
submit()
skip()
skip()
library(swirl)
rm(list=ls())
swirl()
skip()
library(dplyr)
vignette("two-table", package = "dplyr")
skip()
library(nycflights13)
View(airlines)
slice(flights, 1)
?left_join
submit()
skip()
View(weather)
answer02 <- left_join(answer01, weather)
View(answer02)
intersect(colnames(answer01), colnames(weather))
view(airports)
View(airports)
c("origin" = "faa")
answer03 <- left_join(answer02, airports, by = c("origin" = "faa"))
View(answer03)
answer04 <-left_join(airports, answer03, by = c("answer03$dest" = "airports$faa"))
answer04 <-left_join(airports, answer03, by = c("dest" = "faa"))
answer04 <- left_join(answer03, airports, by = c("dest" = "faa"))
colnames(answer04)
skip()
library(stringr)
library(XML)
rm(list = ls())
install.packages(c("stringr", "XML", "maps"))
install.packages(c("stringr", "XML", "maps"))
install.packages(c("stringr", "XML", "maps"))
install.packages(c("stringr", "XML", "maps"))
install.packages(c("stringr", "XML", "maps"))
install.packages(c("stringr", "XML", "maps"))
library(stringr)
library(XML)
library(maps)
heritage_parsed <- htmlParse("https://en.wikipedia.org/wiki/List_of_World_Heritage_in_Danger", encoding = "UTF-8")
heritage_parsed <- htmlParse("https://en.wikipedia.org/wiki/List_of_World_Heritage_in_Danger", encoding = "UTF-8")
tables <- readHTMLTable(heritage_parsed, stringsAsFactors = FALSE)
heritage_parsed <- htmlParse("https://en.wikipedia.org/wiki/List_of_World_Heritage_in_Danger", encoding = "UTF-8")
url <- "http://www.r-datacollection.com/materials/html/fortunes.html"
fortunes <- readLines(con = url)
fortunes
library(XML)
parsed_fortunes <- htmlParse(file = url)
print(parsed_fortunes)
library(XML)
parsed_doc <- htmlParse(file = "fortunes.html")
url <- "http://www.r-datacollection.com/materials/html/fortunes.html"
fortunes <- readLines(con = url)
library(XML)
parsed_doc <- htmlParse(file = "fortunes.html")
library(XML)
parsed_doc <- htmlParse(file = "fortunes")
url <- "http://www.r-datacollection.com/materials/html/fortunes.html"
fortunes <- readLines(con = url)
fortunes
library(XML)
parsed_doc <- htmlParse(file = "fortunes")
2^5
mean(stock.prices)
stock.prices
stock.prices <- c(23,27,23,21,34)
names(stock.prices) <- c(Mon, Tues, Wed, Thu, Fri)
stock.prices
names(stock.prices) <- c(Mon, Tues, Wed, Thu, Fri)
name <- c(Mon, Tues, Wed, Thu, Fri)
names(stock.prices) <- c("Mon", "Tues", "Wed", "Thu", "Fri")
stock.prices
mean(stock.prices)
over.23 <- stock.prices>23
over.23
max(
stock.prices
)
over.23[TRUE]
stock.prices[over.23]
A <- c(1,2,3)
B <- c(4,5,6)
cbind(A,B)
colbind(A,B)
rbind(A,B)
matrix(1:9, 3,3)
mat <- matrix(1:9,byrow=TRUE,nrow = 3)
mat
matrix(1:9)
matrix(1:9,3)
is.matrix(mat)
mat2 <- matrix(1:25,byrow=TRUE,nrow = 5)
mat2
mat2[2,2,3]
mat2[2,2]
mat2[2,2][2,3]
mat2[2,3]
mat2[2:2, 2:3]
mat2[3:2,3:3]
mat2[2:3,2:3]
mat2[4:5,4:5]
sum(mat2)
runif(20)
matrix(runif(20), byrow=TRUE,nrow = 5)
matrix(runif(20), byrow=TRUE,nrow = 4)
source('~/.active-rstudio-document', echo=TRUE)
y <- 0
for (x in c(1:10)) y <- x+y
x <- 1
y
print
{for (x in c(1:10) ) * for(y in c(1:10))}
print
for (x in c(1:10) )
{ x*y
for(y in c(1:10))
}
for(i in 1:5) print(1:i)
for(x in 1:9) print (1:9)
sapply(1:9,function(x) x*1:9)
for(x in 1:9) print (x*1:9)
nums <- sample(10, 10:100)
nums
nums <- sample(10:100, 10)
nums
for (x > 50 || x%%2 == 0 ) print (x "偶數且大於50")
for (x > 50 || x%%2 == 0 ) print (x "偶數且大於50")
x <- 60
for (x > 50 || x%%2 == 0 ) print (x "偶數且大於50")
for (x in x> 50 || x%%2 == 0 ) print (x "偶數且大於50")
x <- 60
for (x in x> 50 || x%%2 == 0 ) print (x "偶數且大於50")
x <- 60
for (x in x> 50 || x%%2 == 0 ) print ("偶數且大於50")
x <- 80
for (x in x> 50 || x%%2 == 0 ) print ("偶數且大於50")
x <- 55
for (x in x> 50 || x%%2 == 0 ) print ("偶數且大於50")
x <- 55
for (x in x> 50 && x%%2 == 0 ) print ("偶數且大於50")
library(rvest)
install.packages("xml2")
install.packages("xml2")
library(rvest)
install.packages("rvest")
install.packages("rvest")
library(rvest)
library(xml2)
library(rvest)
library(XML)
url <- 'http://www.stat-nba.com/team/GSW.html'
dt1 <- readHTMLTable(url,header = T)
dt1
url <- 'http://www.stat-nba.com/team/GSW.html'
url
dt1 <- readHTMLTable(url,header = T)
library(rvest)
library(xml2)
library(rvest)
read_html("https://news.pts.org.tw/list/1")
doc <- read_html("https://news.pts.org.tw/list/1")
doc %>% html_nodes(".list-news-title")
doc %>% html_nodes(".list-news-title a")
doc %>% html_nodes(".list-news-title a") %>% html_attr("href")
doc %>% html_nodes(".list-news-title a") %>% html_text()
library(ggmap)
install.packages(ggmap)
install.packages("ggmap")
install.packages("mapproj")
library(ggmap)
library(mapproj)
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("maps")
library(ggmap)
library(mapproj)
map <- get_map(location = 'Taiwan', zoom = 7)
map
ggmap(map)
map <- get_map(location = 'Taiwan', zoom = 6)
ggmap(map)
map <- get_map(location = 'Taiwan', zoom = 10)
ggmap(map)
map <- get_map(location = 'Taiwan', zoom = 100)
ggmap(map)
map <- get_map(location = 'Taiwan', zoom = 7)
ggmap(map)
map <- get_map(location = 'Taiwan', zoom = 7,language = "zh-TW")
ggmap(map)
map <- get_map(location = c(lon = 120.233937, lat = 22.993013),zoom = 10, language = "zh-TW")
ggmap(map)
map <- get_map(location = c(lon = 25.026647, lat = 121.559601),zoom = 10, language = "zh-TW")
ggmap(map)
map <- get_map(location = c(lon = 25.026647, lat = 121.559601),zoom = 10, language = "zh-TW")
map <- get_map(location = c(lon = 121.559601, lat = 25.026647),zoom = 10, language = "zh-TW")
map <- get_map(location = c(lon = 121.5581794, lat = 25.0270206), language = "zh-TW")
ggmap(map)
map <- get_map(location = c(lon = 121.5581794, lat = 25.0270206),zoom = "auto", language = "zh-TW")
ggmap(map)
map <- get_map(location = c(lon = 121.5581794, lat = 25.0270206),zoom = 100, language = "zh-TW")
ggmap(map)
map <- get_map(location = c(lon = 121.5581794, lat = 25.0270206),zoom = 50, language = "zh-TW")
ggmap(map)
map <- get_map(location = c(lon = 121.5581794, lat = 25.0270206),zoom = 1, language = "zh-TW")
ggmap(map)
map <- get_map(location = c(lon = 121.5581794, lat = 25.0270206),zoom = 10, language = "zh-TW")
ggmap(map)
map <- get_map(location = c(lon = 121.5581794, lat = 25.0270206),zoom = 10, language = "zh-TW",maptype = "roadmap")
ggmap(map)
map <- get_map(location = c(lon = 121.5581794, lat = 25.0270206),zoom = 10, language = "zh-TW",maptype = "toner-lite")
ggmap(map)
ggmap(map, darken = c(0.5, "white"))
ggmap(map, darken = 0.5)
uv <- read.csv("UV_20180320220329.csv")
library(readr)
dataset <- read_csv(NULL)
View(dataset)
uv <- read.csv("UV_20180320220329.csv.csv")
setwd("C:/Users/User/Desktop/R/R")
uv <- read.csv("UV_20180320220329.csv.csv")
uv <- read.csv("UV_20180320220329.csv.csv")
setwd("C:/Users/User/Desktop/R/R/week_3/ggmap")
uv <- read.csv("UV_20180320220329.csv.csv")
uv <- read.csv("UV_20180320220329.csv.csv")
library(readr)
uv <- read_csv("UV_20180320220329.csv")
View(uv)
uv
lon.deg <- sapply((strsplit(as.character(uv$WGS84Lon), ",")), as.numeric)
uv$lon <- lon.deg[1, ] + lon.deg[2, ]/60 + lon.deg[3, ]/3600
lat.deg <- sapply((strsplit(as.character(uv$WGS84Lat), ",")), as.numeric)
uv$lat <- lat.deg[1, ] + lat.deg[2, ]/60 + lat.deg[3, ]/3600
lon.deg <- sapply((strsplit(as.character(uv$WGS84Lon), ",")), as.numeric)
uv$lon <- lon.deg[1, ] + lon.deg[2, ]/60 + lon.deg[3, ]/3600
lat.deg <- sapply((strsplit(as.character(uv$WGS84Lat), ",")), as.numeric)
uv$lat <- lat.deg[1, ] + lat.deg[2, ]/60 + lat.deg[3, ]/3600
lon.deg[1, ]
lon.deg[1,]
lon.deg[,1]
library(ggmap)
map <- get_map(location = 'Taiwan', zoom = 7)
ggmap(map) + geom_point(aes(x = lon, y = lat, size = UVI), data = uv)
lon.deg
uv$lon <- lon.deg[1] + lon.deg[2]/60 + lon.deg[3]/3600
uv$lat <- lat.deg[1] + lat.deg[2]/60 + lat.deg[3]/3600
library(ggmap)
map <- get_map(location = 'Taiwan', zoom = 7)
ggmap(map) + geom_point(aes(x = lon, y = lat, size = UVI), data = uv)
uv$lon <- lon.deg[,1] + lon.deg[,2]/60 + lon.deg[,3]/3600
uv$lat <- lat.deg[,1] + lat.deg[,2]/60 + lat.deg[,3]/3600
